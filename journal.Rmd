---
title: "Journal (reproducible report)"
author: "Kristin Schüler"
date: "2020-11-05"
output:
  html_document:
    toc: true
    toc_float: true
    collapsed: false
    number_sections: true
    toc_depth: 3
    #code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message=FALSE,warning=FALSE, cache=TRUE)
```

**IMPORTANT:** You can delete everything in here and start fresh. You might want to start by not deleting anything above this line until you know what that stuff is doing.

This is an `.Rmd` file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a \# in front of your text, it will create a top level-header.

# First challenge - Sales data analysis 
Date: 2020-28-11
Data Science Basic - WiSe 2020/21  

## Preperation

### Clear the environment and load packages 

```{r}
rm(list=ls())#Clear list
#install.packages("lubridate") #installed the packeges once in the beginning
#install.packages("writexl")

####Load libraries
library(tidyverse)
library(readxl)
library(lubridate)
library(writexl)
library(ggplot2)
library(scales)
library(knitr)
```

### Importing Files

```{r}
Bikes<-read_excel("C:/Users/Kristin/Documents/Working directory/00_data/01_bike_sales/01_raw_data/bikes.xlsx")
Bikeshops<-read_excel("C:/Users/Kristin/Documents/Working directory/00_data/01_bike_sales/01_raw_data/bikeshops.xlsx")
Orderlines<-read_excel("C:/Users/Kristin/Documents/Working directory/00_data/01_bike_sales/01_raw_data/orderlines.xlsx")
```

### Joining Data

```{r}
Summary_table2 <- Orderlines %>% left_join(Bikes, by = c("product.id" = "bike.id"))%>% left_join(Bikeshops, by = c("customer.id" = "bikeshop.id"))
glimpse(Summary_table2, eval=TRUE)
```

## Wrangling and shortening Data

### Wrangling data

```{r}
wrangled_table2<-Summary_table2 %>% 
  separate(col = location, into = c("city", "state_of_sale"),sep = ", ", convert = T) %>% 
  mutate(Total_Amount = quantity*price)%>% 
  select(contains("order"), contains("model"), contains("category"),price, quantity, Total_Amount, everything())%>%  
  rename(bikeshop = name) %>%set_names(names(.) %>% str_replace_all("\\.", "_"))
glimpse(wrangled_table2, eval=TRUE)
```

### Rearranging and shortening wrangled Data

```{r}
Short_table2<-wrangled_table2%>%  select(order_id, order_date, city, state_of_sale, price, quantity, Total_Amount)
glimpse(Short_table2, eval=TRUE)
```

## Business Insights

### Sales by Location

#### Step 1 - Manipulate

```{r}
sales_by_Location<- Short_table2%>%  
  select(state_of_sale, Total_Amount)%>%
  group_by(state_of_sale)%>% 
  summarize(sales = sum(Total_Amount))%>% 
  mutate(sales_in_Euro = scales::dollar(sales, big.mark = ".", 
                                        decimal.mark = ",", 
                                        prefix = "", 
                                        suffix = " €"))
glimpse(sales_by_Location, eval=TRUE)
```

#### Step 2 - Visualize

```{r, fig.width=10, fig.height=10}
sales_by_Location%>%
  ggplot(aes(x = state_of_sale, y = sales)) +
  geom_col(fill = "blue") + 
  geom_label(aes(label = sales_in_Euro)) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  scale_y_continuous(labels = scales::dollar_format(big.mark = ".", 
                                                    decimal.mark = ",", 
                                                    prefix = "", 
                                                    suffix = " €")) + #adjusting to Euros
  labs(title = "Revenue of bike sales by location",
       subtitle = "Bike stores available in 12 states",
       x = "", y = "Revenue")
```

### Sales by Year and Location

##### Step 1 - Manipulate

```{r}
sales_year_Location<- Short_table2%>%  
  select(order_date, Total_Amount, state_of_sale)%>%
  mutate(year=year(order_date))%>%
  group_by(year, state_of_sale)%>% 
  summarize(sales = sum(Total_Amount))%>% 
  ungroup() %>%
  mutate(sales_in_Euro = scales::dollar(sales, big.mark = ".", 
                                        decimal.mark = ",", 
                                        prefix = "", 
                                        suffix = " €"))
glimpse(sales_year_Location, eval=TRUE)
```

#### Step 2 - Visualize

```{r, fig.width=10, fig.height=10}
sales_year_Location%>%
  ggplot(aes(x = year, y = sales, fill = state_of_sale)) +
  geom_col() + 
  facet_wrap(~ state_of_sale) +
  geom_smooth(method = "lm", se = FALSE) +
  scale_y_continuous(labels = scales::dollar_format(big.mark = ".", 
                                                    decimal.mark = ",", 
                                                    prefix = "", 
                                                    suffix = " €")) +
  labs(title = "Trend of bike sale in 12 states of Germany",
       subtitle = "Overall positive trends - North Rhine-Westphalia with most revenues",
       fill = "State")
```

## Writing Files 

### Excel

```{r}
wrangled_table2 %>%
  write_xlsx("C:/Users/Kristin/Documents/Working directory/00_data/01_bike_sales/02_wrangled_data/bike_orderlines_wrangled2.xlsx")
```

### CSV

```{r}
wrangled_table2 %>% 
  write_csv("C:/Users/Kristin/Documents/Working directory/00_data/01_bike_sales/02_wrangled_data/bike_orderlines_wrangled2.csv")
```

### RDS

```{r}
wrangled_table2 %>% 
  write_rds("C:/Users/Kristin/Documents/Working directory/00_data/01_bike_sales/02_wrangled_data/bike_orderlines_wrangled2.rds")
```



# Second Challenge - Data Acquisition 

For now, I am not able to perform this Challenge. I am really (REALLY!) beginner in programming, which means I actually have not done any programming before. Chapter 1 and 2 were okish, but now Chapter 3 is just too much. I know there is Mattermost, but I do not even know what to ask as I have no idea so far what to do and where to start. I will reread the theoretical part and retry next weekend, but might be that I just cannot fulfill this Challenge.
I continued with Part 4 - Data Wrangling which seems to be a bit lighter and easier to understand. 

# Third Challenge - Data Wrangling 

## Preparation 

### Loading Libraries and packages, clear list 

```{r}
rm(list=ls())#Clear list
#install.packages("vroom")
#install.packages("tictoc")
#install.packages("stargazer")
library(tidyverse)
library(vroom)
library(data.table)
library(tictoc)
library(data.table)
library(knitr)
```

### Loading and Importing patent data 

```{r}
col_types_patent <- list(
  id                        = col_character(), #patent_id
  type                      = col_skip(), #not needed
  number                    = col_skip(), #not needed
  country                   = col_skip(), #not needed
  date                      = col_date("%Y-%m-%d"),
  abstract                  = col_skip(), #not needed
  title                     = col_skip(), #not needed
  kind                      = col_skip(), #not needed
  num_claims                = col_skip(), #not needed
  filename                  = col_skip(), #not needed
  withdrawn                 = col_skip()  #not needed
)
patent_table <- vroom(
  file       = "E:/Uni Hamburg/DataScience/patent.tsv/patent.tsv", 
  delim      = "\t", 
  col_types  = col_types_patent,
  na         = c("", "NA", "NULL")
)
# Rename id to patent_id
setnames(patent_table, "id", "patent_id")
glimpse(patent_table, eval = TRUE)
```

### Loading and importing Patent_assignee data

```{r}
col_types_patent_assignee <- list(
  patent_id                 = col_character(),
  assignee_id               = col_character(),
  location_id               = col_skip() #not needed
)

patent_assignee_table <- vroom(
  file       = "E:/Uni Hamburg/DataScience/patent_assignee.tsv/patent_assignee.tsv", 
  delim      = "\t", 
  col_types  = col_types_patent_assignee,
  na         = c("", "NA", "NULL")
)
glimpse(patent_assignee_table, eval = TRUE)
```

### Loading and importing assignee data

```{r}
col_types_assignee <- list(
  id                        = col_character(), #assignee_id
  type                      = col_double(), 
  name_first                = col_skip(), #not needed
  name_last                 = col_skip(), #not needed
  organization              = col_character()
)

assignee_table <- vroom(
  file       = "E:/Uni Hamburg/DataScience/assignee.tsv/assignee.tsv", 
  delim      = "\t", 
  col_types  = col_types_assignee,
  na         = c("", "NA", "NULL")
)
setnames(assignee_table, "id", "assignee_id")
glimpse(assignee_table, eval = TRUE)
```

### Loading and importing USPC Data - USPTO patent classification at patent issue date

```{r}
col_types_uspc <- list(
  uuid                      = col_skip(), #not needed
  patent_id                 = col_character(),
  mainclass_id              = col_double(),
  subclass_id               = col_skip(), #not needed
  sequence                  = col_skip() #not needed
)

uspc_table <- vroom(
  file       = "E:/Uni Hamburg/DataScience/uspc.tsv/uspc.tsv", 
  delim      = "\t", 
  col_types  = col_types_uspc,
  na         = c("", "NA", "NULL")
)
glimpse(uspc_table, eval = TRUE)
```

## Make a data.table out of the imported data

### Patent table

```{r}
class(patent_table)%>%
  glimpse(, eval =TRUE)
setDT(patent_table)
class(patent_table)%>%
  glimpse(, eval =TRUE)
```

### Patent_assignee table

```{r}
setDT(patent_assignee_table)
class(patent_assignee_table)%>%
  glimpse(, eval =TRUE)
```

### Assignee table

```{r}
setDT(assignee_table)
class(assignee_table)%>%
  glimpse(, eval =TRUE)
```

### uspc table

```{r}
setDT(uspc_table)
class(uspc_table)%>%
  glimpse(, eval =TRUE)
```

## Joining data 

### Task 1: Assignee & Patent Assignee

```{r}
combined_data1 <- merge(x = patent_assignee_table, y = assignee_table, 
                        by    = "assignee_id", 
                        all.x = TRUE, 
                        all.y = TRUE)%>%
  filter(!is.na(patent_id)) %>%
  glimpse(, eval = TRUE)
```

### Task 2: Assignee & Patent Assignee & Patent

```{r}
combined_data2<- merge(x=combined_data1, y = patent_table,
                       by    = "patent_id", 
                       all.x = TRUE, 
                       all.y = TRUE)%>%
  filter(!is.na(patent_id))%>%
  glimpse(, eval = TRUE)
```

### Task 3: Assignee & Patent Assignee & Patent

```{r}
combined_data3<- merge(x=combined_data1, y = uspc_table,
                       by    = "patent_id", 
                       all.x = TRUE, 
                       all.y = TRUE)%>%
  filter(!is.na(patent_id))%>%
  filter(!is.na(mainclass_id))%>%
  filter(!is.na(organization))%>%
  select(patent_id, mainclass_id, organization)%>%
  glimpse(, eval = TRUE)
```

## Challenge Tasks

### Task 1: Patent Dominance: What US company / corporation has the most patents? List the 10 US companies with the most assigned/granted patents.

```{r}
most_patents<-combined_data1 %>% 
  filter(type == 2)%>%
  count(organization, sort = T)
setnames(most_patents, "n", "number of patents")
```

The top 10 US companies / corporation with the most patents are the following:

```{r results = 'asis'}
Most<-most_patents[1:10, ]
knitr::kable(
  head(Most[,],10), booktabs = TRUE,
  caption = 'The top 10 innovative companies / corporation in the US with most new patents'
)
```

### Task 2: Recent patent activity: What US company had the most patents granted in 2019? List the top 10 companies with the most new granted patents for 2019.

```{r}
most_patents2019<-combined_data2 %>% 
  separate(col = date, into = c("year", "month", "day"), sep = "-", convert = T)%>%
  filter(year == 2019)%>%
  filter(type == 2)%>%
  count(organization, sort = T)

setnames(most_patents2019, "n", "number of patents")%>%
  glimpse(, eval=TRUE)
```

The top 10 US companies with the most new granted patents for 2019 are the following:

```{r results = 'asis'}
Top10_2019<-most_patents2019[1:10,]
knitr::kable(
  head(Top10_2019[,],10), booktabs = TRUE,
  caption = 'The top 10 innovative companies in the US with most new granted  patents in 2019'
)
``` 

### Task 3: Innovation in Tech: What is the most innovative tech sector? For the top 10 companies (worldwide) with the most patents, what are the top 5 USPTO tech main classes?

```{r}
USPTO_worldwide<-combined_data3 %>%
  count(organization, sort = T)

setnames(USPTO_worldwide, "n", "number of patents")%>%
  glimpse(, eval=TURE)

Top10_worldwide<-USPTO_worldwide[1:10,]

Top_USPTO<- merge(x=Top10_worldwide, y = combined_data3, 
                  by = "organization",
                  all.x = TRUE, 
                  all.y = FALSE)%>%
  count(mainclass_id, sort = T)
setnames(Top_USPTO, "n", "USPTO tech main class occurency")%>%
  glimpse(, eval=TRUE)
```

The top 10 companies worldwide with the most patents including the top 5 USPTO tech main classes:

```{r results = 'asis'}
Top10<-head(USPTO_worldwide, 10)
Top<-head(Top_USPTO, 5)
knitr::kable(
  list(Top10, Top),
  caption = 'The top 10 innovative companies worldwide holding most of the patents (left) and the top 5 USPTO tech main classes (right)'
)
```
